# GA pour l'IA Explicable en Imagerie MÃ©dicale

Ce projet implÃ©mente un systÃ¨me d'intelligence artificielle basÃ© sur l'**AlgÃ¨bre GÃ©omÃ©trique (Geometric Algebra)** pour la classification et l'explication de dÃ©cisions en imagerie mÃ©dicale. Le systÃ¨me permet non seulement de classer les images (tissu sain vs tumeur), mais aussi d'identifier quelles composantes gÃ©omÃ©triques influencent le diagnostic, offrant ainsi une couche d'interprÃ©tabilitÃ© trÃ¨s recherchÃ©e.

## ğŸ¯ Objectifs

- **Classification**: Distinguer les tissus sains des tumeurs dans les images mÃ©dicales
- **ExplicabilitÃ©**: Identifier quelles composantes gÃ©omÃ©triques (scalaires, vecteurs, bivecteurs, trivecteurs) influencent les dÃ©cisions
- **InterprÃ©tabilitÃ©**: Fournir des visualisations et rapports dÃ©taillÃ©s sur les dÃ©cisions du modÃ¨le

## ğŸ“š Concepts de l'AlgÃ¨bre GÃ©omÃ©trique

Le systÃ¨me utilise l'algÃ¨bre de Clifford pour reprÃ©senter les images mÃ©dicales comme des **multivecteurs** :

- **Scalaires (Grade 0)**: IntensitÃ©s de pixels
- **Vecteurs (Grade 1)**: Gradients spatiaux (dx, dy)
- **Bivecteurs (Grade 2)**: Orientations et textures
- **Trivecteurs (Grade 3)**: Relations gÃ©omÃ©triques complexes

Cette reprÃ©sentation permet de capturer des caractÃ©ristiques gÃ©omÃ©triques riches qui sont naturellement interprÃ©tables.

## ğŸ—ï¸ Structure du Projet

```
MastersGA/
â”œâ”€â”€ ga_medical_imaging/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ga_representation.py      # Conversion images â†’ multivecteurs
â”‚   â”œâ”€â”€ model.py                    # ModÃ¨les de classification GA
â”‚   â”œâ”€â”€ explainability.py          # Module d'explicabilitÃ©
â”‚   â”œâ”€â”€ data_utils.py              # Utilitaires pour les donnÃ©es
â”‚   â”œâ”€â”€ train.py                   # Script d'entraÃ®nement
â”‚   â””â”€â”€ evaluate_and_explain.py   # Ã‰valuation et explications
â”œâ”€â”€ example_usage.py               # Exemples d'utilisation
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â””â”€â”€ README.md                      # Ce fichier
```

## ğŸš€ Installation

### Option 1 : Google Colab (RecommandÃ© pour dÃ©buter)

Le moyen le plus simple de tester le projet est d'utiliser le notebook Colab :

1. Ouvrez **[GA_Medical_Imaging_Colab.ipynb](GA_Medical_Imaging_Colab.ipynb)** sur [Google Colab](https://colab.research.google.com/)
2. ExÃ©cutez les cellules dans l'ordre
3. Le notebook contient tout le code nÃ©cessaire (version simplifiÃ©e)

Voir **[COLAB_SETUP.md](COLAB_SETUP.md)** pour plus de dÃ©tails.

### Option 2 : Installation Locale

#### PrÃ©requis

- Python 3.8+
- PyTorch 2.0+
- CUDA (optionnel, pour GPU)

#### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

## ğŸ’» Utilisation

### 1. EntraÃ®nement du modÃ¨le

#### Avec vos propres donnÃ©es

Organisez vos images dans la structure suivante :
```
data/
â”œâ”€â”€ sain/
â”‚   â”œâ”€â”€ image1.png
â”‚   â”œâ”€â”€ image2.png
â”‚   â””â”€â”€ ...
â””â”€â”€ tumeur/
    â”œâ”€â”€ image1.png
    â”œâ”€â”€ image2.png
    â””â”€â”€ ...
```

Puis lancez l'entraÃ®nement :
```bash
python -m ga_medical_imaging.train --data_dir data --num_epochs 50 --batch_size 16
```

#### Avec un dataset factice (pour tester)

Le systÃ¨me peut crÃ©er automatiquement un dataset factice :
```bash
python -m ga_medical_imaging.train --num_epochs 20
```

### 2. Ã‰valuation et gÃ©nÃ©ration d'explications

```bash
python -m ga_medical_imaging.evaluate_and_explain \
    --checkpoint checkpoints/best_model.pth \
    --image path/to/image.png \
    --output_dir explanations
```

### 3. Exemples d'utilisation

Pour voir des exemples complets :
```bash
python example_usage.py
```

## ğŸ“Š FonctionnalitÃ©s d'ExplicabilitÃ©

Le module d'explicabilitÃ© fournit :

1. **Analyse des composantes gÃ©omÃ©triques** : Contribution relative de chaque grade (scalaires, vecteurs, bivecteurs, trivecteurs)

2. **Cartes d'importance spatiale** : Visualisation des rÃ©gions les plus importantes pour la dÃ©cision

3. **Rapports textuels** : Explications dÃ©taillÃ©es en langage naturel

4. **Visualisations** : Graphiques montrant :
   - L'image originale
   - La carte d'importance spatiale
   - Les contributions des diffÃ©rentes composantes
   - Les visualisations des scalaires, vecteurs et bivecteurs

## ğŸ”¬ Architecture du ModÃ¨le

### GAMedicalClassifier

Le modÃ¨le principal comprend :

1. **GeometricAlgebraRepresentation** : Convertit les images en multivecteurs
2. **GAFeatureExtractor** : Extrait des caractÃ©ristiques gÃ©omÃ©triques via des couches GA
3. **Classifier** : Couches de classification finales

### GAMultivectorLayer

Couche personnalisÃ©e qui opÃ¨re sur les multivecteurs en utilisant le produit gÃ©omÃ©trique, permettant au modÃ¨le d'apprendre des relations gÃ©omÃ©triques complexes.

## ğŸ“ˆ MÃ©triques et Ã‰valuation

Le systÃ¨me suit :
- **PrÃ©cision d'entraÃ®nement et de validation**
- **Perte d'entraÃ®nement et de validation**
- **Contributions des composantes gÃ©omÃ©triques**
- **Cartes d'attention spatiale**

Les rÃ©sultats sont sauvegardÃ©s dans TensorBoard (si activÃ©) et dans les checkpoints.

## ğŸ¨ Visualisations

Les visualisations gÃ©nÃ©rÃ©es incluent :

- **Image originale** : L'image mÃ©dicale d'entrÃ©e
- **Carte d'importance** : RÃ©gions importantes pour la dÃ©cision
- **Graphique de contributions** : Barres montrant l'importance de chaque composante
- **Composantes individuelles** : Visualisations des scalaires, vecteurs et bivecteurs
- **ProbabilitÃ©s de prÃ©diction** : Confiance du modÃ¨le pour chaque classe

## ğŸ”§ ParamÃ¨tres Configurables

### EntraÃ®nement
- `--num_epochs` : Nombre d'Ã©poques (dÃ©faut: 50)
- `--batch_size` : Taille du batch (dÃ©faut: 16)
- `--learning_rate` : Taux d'apprentissage (dÃ©faut: 0.001)
- `--image_size` : Taille des images (dÃ©faut: 224 224)

### ModÃ¨le
- `multivector_dim` : Dimension des multivecteurs (8 pour GA 3D)
- `feature_dim` : Dimension des caractÃ©ristiques extraites (128)
- `num_classes` : Nombre de classes (2 pour binaire)

## ğŸ“ Exemple de Rapport d'Explication

```
=== RAPPORT D'EXPLICATION - DIAGNOSTIC MÃ‰DICAL ===

PRÃ‰DICTION:
  Classe prÃ©dite: Tumeur
  Confiance: 87.3%
  
CONTRIBUTION DES COMPOSANTES GÃ‰OMÃ‰TRIQUES:

1. Scalaires (IntensitÃ©s de pixels):
   Contribution: 25.3%
   
2. Vecteurs (Gradients spatiaux):
   Contribution: 30.1%
   
3. Bivecteurs (Orientations et textures):
   Contribution: 35.2%
   
4. Trivecteur (Relations complexes):
   Contribution: 9.4%

ANALYSE:
La composante la plus influente est les orientations et textures 
(35.2% de la contribution totale).
```

## ğŸ§ª Tests et Validation

Pour tester le systÃ¨me avec des donnÃ©es factices :

```python
from ga_medical_imaging.data_utils import create_dummy_dataset
from ga_medical_imaging.model import GAMedicalClassifier

# CrÃ©er un dataset factice
image_paths, labels = create_dummy_dataset(num_samples=100)

# CrÃ©er et tester le modÃ¨le
model = GAMedicalClassifier(num_classes=2, device='cpu')
# ... entraÃ®nement et Ã©valuation
```

## ğŸ”¬ Contributions de Recherche

Ce projet prÃ©sente plusieurs contributions originales dans le domaine de l'IA explicable en imagerie mÃ©dicale :

### Contributions Principales

1. **ReprÃ©sentation Multivecteur pour Images MÃ©dicales** : DÃ©veloppement d'un schÃ©ma de conversion d'images mÃ©dicales en reprÃ©sentations multivecteurs GA qui capture explicitement diffÃ©rentes dimensions gÃ©omÃ©triques (scalaires, vecteurs, bivecteurs, trivecteurs).

2. **Couches Neuronales sur Multivecteurs** : ImplÃ©mentation de couches spÃ©cialisÃ©es (`GAMultivectorLayer`) opÃ©rant directement sur les multivecteurs avec produits gÃ©omÃ©triques adaptÃ©s.

3. **ExplicabilitÃ© IntrinsÃ¨que** : SystÃ¨me d'explication basÃ© sur les composantes gÃ©omÃ©triques, fournissant des explications structurelles plutÃ´t que post-hoc.

4. **Analyse de Contribution des Composantes** : MÃ©thode pour quantifier la contribution relative de chaque grade gÃ©omÃ©trique dans les dÃ©cisions de classification.

5. **Architecture End-to-End Explicable** : Conception d'une architecture complÃ¨te qui maintient l'interprÃ©tabilitÃ© Ã  chaque Ã©tape du pipeline.

Pour plus de dÃ©tails sur les contributions, voir **[CONTRIBUTIONS.md](CONTRIBUTIONS.md)**.

Pour le plan d'expÃ©rimentation, voir **[EXPERIMENTS.md](EXPERIMENTS.md)**.

## ğŸ“š RÃ©fÃ©rences

Ce projet s'inspire de :
- Geometric Algebra pour la reprÃ©sentation des donnÃ©es
- Explainable AI (XAI) pour l'interprÃ©tabilitÃ©
- Medical Image Analysis pour l'application

## ğŸ¤ Contribution

Pour contribuer au projet :
1. Fork le repository
2. CrÃ©ez une branche pour votre fonctionnalitÃ©
3. Committez vos changements
4. Poussez vers la branche
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est destinÃ© Ã  des fins de recherche et d'Ã©ducation.

## ğŸ“– Documentation de Recherche

Ce projet fait partie d'un travail de recherche de master. La documentation complÃ¨te inclut :

- **[RESEARCH_REPORT.md](RESEARCH_REPORT.md)** : **Rapport de recherche complet** (mÃ©thodologie, contributions, cadre expÃ©rimental)
- **[CONTRIBUTIONS.md](CONTRIBUTIONS.md)** : Contributions dÃ©taillÃ©es de ce travail
- **[CONTRIBUTIONS_SUMMARY.md](CONTRIBUTIONS_SUMMARY.md)** : RÃ©sumÃ© concis des contributions
- **[EXPERIMENTS.md](EXPERIMENTS.md)** : Plan d'expÃ©rimentation et Ã©valuation
- **[RESEARCH_PAPER_OUTLINE.md](RESEARCH_PAPER_OUTLINE.md)** : Plan de rÃ©daction du mÃ©moire
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** : Guide de rÃ©fÃ©rence rapide

Pour gÃ©nÃ©rer un rÃ©sumÃ© automatique des contributions :
```bash
python scripts/generate_contribution_summary.py
```

## ğŸ”® AmÃ©liorations Futures

- [ ] Support pour images 3D (volumes mÃ©dicaux)
- [ ] IntÃ©gration avec d'autres architectures (Transformers GA)
- [ ] MÃ©triques d'explicabilitÃ© quantitatives
- [ ] Interface web pour la visualisation interactive
- [ ] Support pour multi-classes (plusieurs types de tumeurs)

## ğŸ“§ Contact

Pour toute question ou suggestion, n'hÃ©sitez pas Ã  ouvrir une issue.

---

**Note**: Ce systÃ¨me est conÃ§u pour la recherche et l'Ã©ducation. Pour une utilisation clinique rÃ©elle, des validations supplÃ©mentaires et des certifications appropriÃ©es sont nÃ©cessaires.

# GA-for-explainable-AI-in-medical-imaging
